# 9. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¦¬ëª¨ë¸ë§

## ğŸ—ï¸ DN_SOLUTION2 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë¦¬ëª¨ë¸ë§

### 9.1 í˜„ì¬ ì•„í‚¤í…ì²˜ ë¶„ì„

#### 9.1.1 í˜„ì¬ ì‹œìŠ¤í…œ êµ¬ì¡°
```
í˜„ì¬ ì•„í‚¤í…ì²˜: Monolithic Architecture
â”œâ”€â”€ Frontend: React + Redux + Material-UI
â”œâ”€â”€ Backend: Django + DRF + PostgreSQL
â”œâ”€â”€ Authentication: JWT Token
â”œâ”€â”€ Storage: Local File System
â””â”€â”€ Deployment: Single Server
```

#### 9.1.2 í˜„ì¬ ì‹œìŠ¤í…œì˜ í•œê³„
```
í™•ì¥ì„± í•œê³„:
- ëª¨ë†€ë¦¬ì‹ êµ¬ì¡°ë¡œ ì¸í•œ ê°œë³„ ê¸°ëŠ¥ í™•ì¥ ì–´ë ¤ì›€
- ë‹¨ì¼ ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì¸í•œ ì„±ëŠ¥ ë³‘ëª©
- í”„ë¡ íŠ¸ì—”ë“œ/ë°±ì—”ë“œ ê²°í•©ë„ ë†’ìŒ

ì„±ëŠ¥ í•œê³„:
- ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¶€ì¡±
- ëŒ€ìš©ëŸ‰ ì—‘ì…€ ì²˜ë¦¬ ì‹œ ì„œë²„ ë¶€í•˜
- ìºì‹± ì „ëµ ë¶€ì¡±

ìš´ì˜ í•œê³„:
- ë°°í¬ ë‹¨ìœ„ê°€ í¬ê³  ìœ„í—˜ë„ ë†’ìŒ
- ê°œë³„ ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§ ì–´ë ¤ì›€
- ì¥ì•  ê²©ë¦¬ ë¶ˆê°€
```

### 9.2 ë¦¬ëª¨ë¸ë§ ì•„í‚¤í…ì²˜ ì„¤ê³„

#### 9.2.1 ì „ì²´ ì•„í‚¤í…ì²˜ ê°œìš”
```
Target Architecture: Modular Monolith â†’ Microservices Ready

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client Tier   â”‚    â”‚  Application    â”‚    â”‚   Data Tier     â”‚
â”‚                 â”‚    â”‚     Tier        â”‚    â”‚                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ React SPA   â”‚â—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ API Gateway â”‚ â”‚    â”‚ â”‚ PostgreSQL  â”‚ â”‚
â”‚ â”‚             â”‚ â”‚    â”‚ â”‚             â”‚ â”‚    â”‚ â”‚ (Primary)   â”‚ â”‚
â”‚ â”‚ - HQ Portal â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ - Agency    â”‚ â”‚    â”‚        â”‚        â”‚    â”‚        â”‚        â”‚
â”‚ â”‚ - Retail    â”‚ â”‚    â”‚        â–¼        â”‚    â”‚        â–¼        â”‚
â”‚ â”‚             â”‚ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ Core API    â”‚ â”‚    â”‚ â”‚ Redis       â”‚ â”‚
â”‚        â”‚        â”‚    â”‚ â”‚ Services    â”‚ â”‚    â”‚ â”‚ (Cache)     â”‚ â”‚
â”‚        â–¼        â”‚    â”‚ â”‚             â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚    â”‚        â”‚        â”‚
â”‚ â”‚ Mobile PWA  â”‚ â”‚    â”‚ â”‚ â”‚ Auth    â”‚ â”‚ â”‚    â”‚        â–¼        â”‚
â”‚ â”‚ (Optional)  â”‚ â”‚    â”‚ â”‚ â”‚ Service â”‚ â”‚ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚    â”‚ â”‚ File Store  â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚    â”‚ â”‚ (S3/Local)  â”‚ â”‚
                       â”‚ â”‚ â”‚ Policy  â”‚ â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚ â”‚ â”‚ Service â”‚ â”‚ â”‚    â”‚        â”‚        â”‚
â”‚ External APIs   â”‚    â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚    â”‚        â–¼        â”‚
â”‚                 â”‚    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ â”‚ Order   â”‚ â”‚ â”‚    â”‚ â”‚ Message     â”‚ â”‚
â”‚ â”‚ SMS Service â”‚â—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ â”‚ Service â”‚ â”‚ â”‚    â”‚ â”‚ Queue       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚    â”‚ â”‚ (Redis)     â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ Email       â”‚â—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ â”‚ Rebate  â”‚ â”‚ â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ Service     â”‚ â”‚    â”‚ â”‚ â”‚ Service â”‚ â”‚ â”‚                      
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚    â”‚ Infrastructure  â”‚
â”‚ â”‚ Push        â”‚â—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ â”‚ Report  â”‚ â”‚ â”‚    â”‚                 â”‚
â”‚ â”‚ Notificationâ”‚ â”‚    â”‚ â”‚ â”‚ Service â”‚ â”‚ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚    â”‚ â”‚ Docker      â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚ Containers  â”‚ â”‚
                       â”‚        â”‚        â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚        â–¼        â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ Monitoring      â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ Nginx       â”‚ â”‚
â”‚                 â”‚    â”‚ â”‚ WebSocket   â”‚ â”‚    â”‚ â”‚ (Reverse    â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ Service     â”‚ â”‚    â”‚ â”‚  Proxy)     â”‚ â”‚
â”‚ â”‚ Prometheus  â”‚â—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ (Real-time) â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚        â”‚        â”‚    â”‚ â”‚ SSL/TLS     â”‚ â”‚
â”‚ â”‚ Grafana     â”‚ â”‚    â”‚        â–¼        â”‚    â”‚ â”‚ (Let's      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚  Encrypt)   â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”‚ Background  â”‚ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ ELK Stack   â”‚â—„â”¼â”€â”€â”€â”€â”¼â–ºâ”‚ Jobs        â”‚ â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ (Logging)   â”‚ â”‚    â”‚ â”‚ (Celery)    â”‚ â”‚                      
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                      
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      
```

#### 9.2.2 ëª¨ë“ˆí™” ì „ëµ
```python
# ì„œë¹„ìŠ¤ ë¶„ë¦¬ ì „ëµ
MODULAR_SERVICES = {
    'auth_service': {
        'responsibility': 'Authentication & Authorization',
        'components': ['JWT Management', 'Role-based Access Control', 'Session Management'],
        'database': 'Shared PostgreSQL',
        'independence_level': 'Low'
    },
    
    'policy_service': {
        'responsibility': 'Policy Management & Distribution',
        'components': ['Policy CRUD', 'Group Management', 'Form Builder', 'Rebate Matrix'],
        'database': 'Dedicated Schema',
        'independence_level': 'High'
    },
    
    'order_service': {
        'responsibility': 'Order Processing & Workflow',
        'components': ['Order Creation', 'Approval Workflow', 'Status Management'],
        'database': 'Dedicated Schema',
        'independence_level': 'High'
    },
    
    'rebate_service': {
        'responsibility': 'Rebate Allocation & Settlement',
        'components': ['Allocation', 'Distribution', 'Usage Tracking', 'Settlement'],
        'database': 'Dedicated Schema',
        'independence_level': 'Medium'
    },
    
    'company_service': {
        'responsibility': 'Company & User Management',
        'components': ['Company CRUD', 'Hierarchy Management', 'User Management'],
        'database': 'Shared PostgreSQL',
        'independence_level': 'Low'
    },
    
    'report_service': {
        'responsibility': 'Reporting & Excel Generation',
        'components': ['Data Aggregation', 'Excel Generation', 'File Management'],
        'database': 'Read-only Replicas',
        'independence_level': 'Medium'
    },
    
    'notification_service': {
        'responsibility': 'Real-time Communication',
        'components': ['WebSocket Management', 'Push Notifications', 'Email/SMS'],
        'database': 'Redis + Message Queue',
        'independence_level': 'High'
    }
}
```

### 9.3 ë°ì´í„° ì•„í‚¤í…ì²˜ ì„¤ê³„

#### 9.3.1 ë°ì´í„°ë² ì´ìŠ¤ ë¶„ë¦¬ ì „ëµ
```sql
-- í˜„ì¬: Single Database
-- ëª©í‘œ: Schema-based Separation (ë‹¨ê³„ì  ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì¤€ë¹„)

-- Core Schema (ê³µí†µ)
CREATE SCHEMA core;
-- Tables: companies, company_users, telecom_providers, plans

-- Policy Schema
CREATE SCHEMA policy;
-- Tables: policies, policy_groups, policy_group_assignments, 
--         policy_rebates, order_form_fields, policy_form_fields

-- Order Schema  
CREATE SCHEMA orders;
-- Tables: customer_orders, order_status_logs, order_attachments

-- Rebate Schema
CREATE SCHEMA rebate;
-- Tables: rebate_allocations, rebate_settlements, 
--         settlement_approvals, settlement_summaries

-- Analytics Schema (Read-only)
CREATE SCHEMA analytics;
-- Views: aggregated data for reporting
```

#### 9.3.2 ìºì‹± ì „ëµ
```python
# Redis ìºì‹± êµ¬ì¡°
CACHE_STRUCTURE = {
    # ì •ì±… ìºì‹œ (5ë¶„)
    'policy:list:{company_type}:{company_id}': 'JSON',
    'policy:detail:{policy_id}': 'JSON', 
    'policy:form_schema:{policy_id}': 'JSON',
    'policy:rebate_matrix:{policy_id}': 'JSON',
    
    # ì‚¬ìš©ì ì„¸ì…˜ (30ë¶„)
    'user:session:{user_id}': 'JSON',
    'user:permissions:{user_id}': 'SET',
    'user:company:{user_id}': 'JSON',
    
    # ëŒ€ì‹œë³´ë“œ ë°ì´í„° (2ë¶„)
    'dashboard:{company_type}:{company_id}': 'JSON',
    
    # ì£¼ë¬¸ ë¦¬ìŠ¤íŠ¸ (1ë¶„)
    'orders:list:{company_id}:{filters_hash}': 'JSON',
    
    # ë¦¬ë² ì´íŠ¸ ì”ì•¡ (ì‹¤ì‹œê°„)
    'rebate:balance:{company_id}': 'DECIMAL',
    
    # ì—‘ì…€ ì‘ì—… ìƒíƒœ (1ì‹œê°„)
    'excel:task:{task_id}': 'JSON',
}

# ìºì‹œ ë¬´íš¨í™” ì „ëµ
CACHE_INVALIDATION = {
    'policy_updated': [
        'policy:list:*',
        'policy:detail:{policy_id}',
        'policy:form_schema:{policy_id}',
        'policy:rebate_matrix:{policy_id}'
    ],
    'order_created': [
        'orders:list:{company_id}:*',
        'dashboard:{company_type}:{company_id}',
        'rebate:balance:{company_id}'
    ],
    'rebate_allocated': [
        'rebate:balance:{company_id}',
        'dashboard:{company_type}:{company_id}'
    ]
}
```

### 9.4 API Gateway ì„¤ê³„

#### 9.4.1 API Gateway êµ¬ì¡°
```python
# api_gateway/routes.py
API_ROUTES = {
    # Authentication Routes
    '/api/auth/*': {
        'service': 'auth_service',
        'rate_limit': '100/minute',
        'cache': False,
        'auth_required': False
    },
    
    # Policy Routes
    '/api/policies/*': {
        'service': 'policy_service', 
        'rate_limit': '200/minute',
        'cache': True,
        'cache_ttl': 300,  # 5 minutes
        'auth_required': True
    },
    
    # Order Routes
    '/api/orders/*': {
        'service': 'order_service',
        'rate_limit': '300/minute', 
        'cache': False,
        'auth_required': True
    },
    
    # Rebate Routes
    '/api/rebates/*': {
        'service': 'rebate_service',
        'rate_limit': '150/minute',
        'cache': True,
        'cache_ttl': 60,  # 1 minute
        'auth_required': True
    },
    
    # Company Routes
    '/api/companies/*': {
        'service': 'company_service',
        'rate_limit': '100/minute',
        'cache': True, 
        'cache_ttl': 600,  # 10 minutes
        'auth_required': True
    },
    
    # Export Routes
    '/api/exports/*': {
        'service': 'report_service',
        'rate_limit': '10/minute',  # ë‚®ì€ ì œí•œ
        'cache': False,
        'auth_required': True,
        'timeout': 300  # 5 minutes
    }
}

# Gateway Middleware
class APIGatewayMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response
        
    def __call__(self, request):
        # 1. Rate Limiting
        if not self.check_rate_limit(request):
            return JsonResponse({'error': 'Rate limit exceeded'}, status=429)
        
        # 2. Authentication
        if not self.check_authentication(request):
            return JsonResponse({'error': 'Authentication required'}, status=401)
        
        # 3. Route to Service
        service_response = self.route_to_service(request)
        
        # 4. Response Processing
        return self.process_response(service_response)
    
    def check_rate_limit(self, request):
        """Rate limiting ì²´í¬"""
        client_id = self.get_client_id(request)
        route_config = self.get_route_config(request.path)
        
        if not route_config:
            return True
            
        rate_limit = route_config.get('rate_limit')
        if not rate_limit:
            return True
            
        # Redisë¥¼ ì´ìš©í•œ Rate Limiting
        return self.redis_rate_limit(client_id, rate_limit)
    
    def route_to_service(self, request):
        """í•´ë‹¹ ì„œë¹„ìŠ¤ë¡œ ë¼ìš°íŒ…"""
        route_config = self.get_route_config(request.path)
        service_name = route_config['service']
        
        # ìºì‹œ í™•ì¸
        if route_config.get('cache'):
            cached_response = self.get_cached_response(request)
            if cached_response:
                return cached_response
        
        # ì„œë¹„ìŠ¤ í˜¸ì¶œ
        response = self.call_service(service_name, request)
        
        # ìºì‹œ ì €ì¥
        if route_config.get('cache') and response.status_code == 200:
            self.cache_response(request, response, route_config.get('cache_ttl', 300))
        
        return response
```

### 9.5 ì‹¤ì‹œê°„ í†µì‹  ì•„í‚¤í…ì²˜

#### 9.5.1 WebSocket ì•„í‚¤í…ì²˜
```python
# websocket/architecture.py
WEBSOCKET_ARCHITECTURE = {
    'connection_management': {
        'type': 'Redis-backed Channel Layer',
        'scaling': 'Multiple Django instances',
        'persistence': 'Redis Cluster',
        'fallback': 'Database notifications'
    },
    
    'message_types': {
        'order_notifications': {
            'targets': ['hq', 'agency', 'retail'],
            'events': ['created', 'approved', 'rejected', 'shipped'],
            'priority': 'high'
        },
        'rebate_notifications': {
            'targets': ['hq', 'agency', 'retail'],
            'events': ['allocated', 'distributed', 'used'],
            'priority': 'medium'
        },
        'policy_notifications': {
            'targets': ['agency', 'retail'],
            'events': ['assigned', 'updated'],
            'priority': 'medium'
        },
        'system_notifications': {
            'targets': ['all'],
            'events': ['maintenance', 'update'],
            'priority': 'low'
        }
    },
    
    'routing_strategy': {
        'company_based': {
            'pattern': 'notifications_{company_id}',
            'use_case': 'Company-specific notifications'
        },
        'role_based': {
            'pattern': 'role_{company_type}',
            'use_case': 'Role-specific broadcasts'
        },
        'user_based': {
            'pattern': 'user_{user_id}',
            'use_case': 'Personal notifications'
        }
    }
}

# WebSocket Connection Manager
class WebSocketManager:
    def __init__(self):
        self.redis_client = redis.StrictRedis(
            host=settings.REDIS_HOST,
            port=settings.REDIS_PORT,
            db=settings.REDIS_WEBSOCKET_DB
        )
    
    async def notify_company(self, company_id, notification_data):
        """ì—…ì²´ë³„ ì•Œë¦¼"""
        channel_layer = get_channel_layer()
        await channel_layer.group_send(
            f'notifications_{company_id}',
            {
                'type': 'notification_message',
                'data': notification_data
            }
        )
    
    async def notify_role(self, role, notification_data):
        """ì—­í• ë³„ ì•Œë¦¼"""
        channel_layer = get_channel_layer()
        await channel_layer.group_send(
            f'role_{role}',
            {
                'type': 'notification_message', 
                'data': notification_data
            }
        )
    
    async def notify_user(self, user_id, notification_data):
        """ê°œì¸ë³„ ì•Œë¦¼"""
        channel_layer = get_channel_layer()
        await channel_layer.group_send(
            f'user_{user_id}',
            {
                'type': 'notification_message',
                'data': notification_data
            }
        )
    
    def get_connection_stats(self):
        """ì—°ê²° í†µê³„"""
        return {
            'total_connections': self.redis_client.scard('active_connections'),
            'company_groups': self.redis_client.keys('notifications_*'),
            'role_groups': self.redis_client.keys('role_*'),
            'user_groups': self.redis_client.keys('user_*')
        }
```

### 9.6 ë³´ì•ˆ ì•„í‚¤í…ì²˜

#### 9.6.1 ì¸ì¦ ë° ê¶Œí•œ ì‹œìŠ¤í…œ
```python
# security/architecture.py
SECURITY_ARCHITECTURE = {
    'authentication': {
        'primary': 'JWT (Access + Refresh Token)',
        'session_management': 'Redis-based',
        'token_rotation': 'Automatic refresh',
        'multi_device': 'Supported'
    },
    
    'authorization': {
        'model': 'RBAC (Role-Based Access Control)',
        'levels': ['Company Type', 'Role', 'Resource'],
        'inheritance': 'Hierarchical permissions',
        'caching': 'Redis-cached permissions'
    },
    
    'data_protection': {
        'encryption_at_rest': 'AES-256',
        'encryption_in_transit': 'TLS 1.3',
        'sensitive_data': 'Field-level encryption',
        'key_management': 'HashiCorp Vault (Future)'
    },
    
    'api_security': {
        'rate_limiting': 'Redis-based sliding window',
        'input_validation': 'DRF Serializers',
        'output_sanitization': 'Custom serializers',
        'cors': 'Whitelist-based'
    }
}

# Permission System
class EnhancedPermissionSystem:
    def __init__(self):
        self.redis_client = redis.StrictRedis()
    
    def check_permission(self, user, action, resource, resource_id=None):
        """í–¥ìƒëœ ê¶Œí•œ í™•ì¸"""
        cache_key = f'perm:{user.id}:{action}:{resource}:{resource_id}'
        
        # ìºì‹œ í™•ì¸
        cached_result = self.redis_client.get(cache_key)
        if cached_result is not None:
            return cached_result.decode() == 'True'
        
        # ê¶Œí•œ ê³„ì‚°
        has_permission = self._calculate_permission(user, action, resource, resource_id)
        
        # ìºì‹œ ì €ì¥ (5ë¶„)
        self.redis_client.setex(cache_key, 300, str(has_permission))
        
        return has_permission
    
    def _calculate_permission(self, user, action, resource, resource_id):
        """ê¶Œí•œ ê³„ì‚° ë¡œì§"""
        company_user = user.company_user
        company = company_user.company
        
        # íšŒì‚¬ íƒ€ì…ë³„ ê¸°ë³¸ ê¶Œí•œ
        base_permissions = self.get_base_permissions(company.type)
        if not base_permissions.get(resource, {}).get(action, False):
            return False
        
        # ë¦¬ì†ŒìŠ¤ë³„ ì„¸ë¶€ ê¶Œí•œ í™•ì¸
        if resource_id:
            return self.check_resource_permission(company, action, resource, resource_id)
        
        return True
    
    def invalidate_user_cache(self, user_id):
        """ì‚¬ìš©ì ê¶Œí•œ ìºì‹œ ë¬´íš¨í™”"""
        pattern = f'perm:{user_id}:*'
        keys = self.redis_client.keys(pattern)
        if keys:
            self.redis_client.delete(*keys)
```

### 9.7 ì„±ëŠ¥ ìµœì í™” ì•„í‚¤í…ì²˜

#### 9.7.1 ìºì‹± ê³„ì¸µ ì„¤ê³„
```python
# caching/layers.py
CACHING_LAYERS = {
    'L1_Application_Cache': {
        'type': 'In-Memory (Django Cache)',
        'ttl': '30 seconds',
        'use_case': 'Hot data, frequent access',
        'examples': ['User sessions', 'Active policies']
    },
    
    'L2_Distributed_Cache': {
        'type': 'Redis Cluster',
        'ttl': '5-60 minutes',
        'use_case': 'Shared data across instances',
        'examples': ['Policy lists', 'Company hierarchy', 'Form schemas']
    },
    
    'L3_Database_Cache': {
        'type': 'PostgreSQL Query Cache',
        'ttl': 'Until data change',
        'use_case': 'Complex query results',
        'examples': ['Aggregated reports', 'Statistics']
    },
    
    'CDN_Cache': {
        'type': 'CloudFlare/AWS CloudFront',
        'ttl': '1 hour - 1 day',
        'use_case': 'Static assets',
        'examples': ['JS/CSS bundles', 'Images', 'Fonts']
    }
}

# Cache Manager
class CacheManager:
    def __init__(self):
        self.redis_client = redis.StrictRedis()
        self.local_cache = {}
    
    def get(self, key, fetch_function=None, ttl=300):
        """ë‹¤ì¸µ ìºì‹œ ì¡°íšŒ"""
        # L1: Local cache
        if key in self.local_cache:
            if not self._is_expired(self.local_cache[key]):
                return self.local_cache[key]['data']
        
        # L2: Redis cache
        redis_data = self.redis_client.get(key)
        if redis_data:
            data = json.loads(redis_data)
            # L1ì— ë³µì‚¬
            self.local_cache[key] = {
                'data': data,
                'expires_at': time.time() + 30  # 30ì´ˆ ë¡œì»¬ ìºì‹œ
            }
            return data
        
        # L3: Database fetch
        if fetch_function:
            data = fetch_function()
            self.set(key, data, ttl)
            return data
        
        return None
    
    def set(self, key, data, ttl=300):
        """ë‹¤ì¸µ ìºì‹œ ì €ì¥"""
        # L1: Local cache (30ì´ˆ)
        self.local_cache[key] = {
            'data': data,
            'expires_at': time.time() + 30
        }
        
        # L2: Redis cache
        self.redis_client.setex(key, ttl, json.dumps(data, default=str))
    
    def invalidate(self, pattern):
        """ìºì‹œ ë¬´íš¨í™”"""
        # Local cache
        keys_to_remove = [k for k in self.local_cache.keys() if fnmatch.fnmatch(k, pattern)]
        for key in keys_to_remove:
            del self.local_cache[key]
        
        # Redis cache
        redis_keys = self.redis_client.keys(pattern)
        if redis_keys:
            self.redis_client.delete(*redis_keys)
```

#### 9.7.2 ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```python
# database/optimization.py
DATABASE_OPTIMIZATION = {
    'read_replicas': {
        'master': 'Write operations',
        'replica_1': 'Report queries',
        'replica_2': 'Dashboard queries',
        'load_balancing': 'Round-robin'
    },
    
    'connection_pooling': {
        'pool_size': 20,
        'max_overflow': 30,
        'pool_timeout': 30,
        'pool_recycle': 3600
    },
    
    'query_optimization': {
        'indexing_strategy': 'Compound indexes for common queries',
        'query_analysis': 'EXPLAIN ANALYZE for slow queries',
        'orm_optimization': 'select_related, prefetch_related',
        'raw_queries': 'For complex aggregations'
    }
}

# Database Router
class DatabaseRouter:
    """ë°ì´í„°ë² ì´ìŠ¤ ë¼ìš°íŒ…"""
    
    def db_for_read(self, model, **hints):
        """ì½ê¸° ì‘ì—… ë¼ìš°íŒ…"""
        if model._meta.app_label in ['reports', 'analytics']:
            return 'replica'
        return 'default'
    
    def db_for_write(self, model, **hints):
        """ì“°ê¸° ì‘ì—… ë¼ìš°íŒ…"""
        return 'default'
    
    def allow_migrate(self, db, app_label, model_name=None, **hints):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ í—ˆìš©"""
        if db == 'replica':
            return False
        return True

# Query Optimizer
class QueryOptimizer:
    @staticmethod
    def optimize_order_queries():
        """ì£¼ë¬¸ ì¿¼ë¦¬ ìµœì í™”"""
        return CustomerOrder.objects.select_related(
            'company',
            'policy',
            'selected_plan__telecom_provider',
            'created_by'
        ).prefetch_related(
            'order_status_logs',
            'order_attachments'
        )
    
    @staticmethod
    def optimize_policy_queries():
        """ì •ì±… ì¿¼ë¦¬ ìµœì í™”"""
        return Policy.objects.select_related(
            'created_by__company'
        ).prefetch_related(
            Prefetch(
                'policy_rebates',
                queryset=PolicyRebate.objects.select_related('telecom_provider')
            ),
            Prefetch(
                'policy_form_fields',
                queryset=PolicyFormField.objects.select_related('field').order_by('order_index')
            )
        )
```

### 9.8 ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì•„í‚¤í…ì²˜

#### 9.8.1 ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ
```python
# monitoring/stack.py
MONITORING_STACK = {
    'metrics': {
        'collector': 'Prometheus',
        'storage': 'Time-series DB',
        'visualization': 'Grafana',
        'alerting': 'Prometheus Alertmanager'
    },
    
    'logging': {
        'collection': 'Fluentd/Filebeat',
        'processing': 'Logstash',
        'storage': 'Elasticsearch',
        'visualization': 'Kibana'
    },
    
    'tracing': {
        'instrumentation': 'Django-OpenTelemetry',
        'collection': 'Jaeger/Zipkin',
        'analysis': 'Distributed tracing'
    },
    
    'uptime': {
        'external': 'Pingdom/UptimeRobot',
        'internal': 'Health check endpoints'
    }
}

# Custom Metrics
class MetricsCollector:
    def __init__(self):
        self.redis_client = redis.StrictRedis()
    
    def record_api_call(self, endpoint, method, status_code, response_time):
        """API í˜¸ì¶œ ë©”íŠ¸ë¦­"""
        metrics = {
            'endpoint': endpoint,
            'method': method,
            'status_code': status_code,
            'response_time': response_time,
            'timestamp': time.time()
        }
        
        # Prometheus ë©”íŠ¸ë¦­
        api_calls_total.labels(
            endpoint=endpoint,
            method=method,
            status=status_code
        ).inc()
        
        api_response_time.labels(
            endpoint=endpoint
        ).observe(response_time)
    
    def record_business_metric(self, metric_type, value, labels=None):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­"""
        if metric_type == 'order_created':
            orders_total.labels(**(labels or {})).inc()
        elif metric_type == 'rebate_allocated':
            rebate_allocated_total.labels(**(labels or {})).inc(value)
        elif metric_type == 'policy_assigned':
            policies_assigned_total.labels(**(labels or {})).inc()

# Health Check System
class HealthChecker:
    def check_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸"""
        try:
            from django.db import connection
            with connection.cursor() as cursor:
                cursor.execute("SELECT 1")
            return {'status': 'healthy', 'response_time': 0.001}
        except Exception as e:
            return {'status': 'unhealthy', 'error': str(e)}
    
    def check_redis(self):
        """Redis ìƒíƒœ í™•ì¸"""
        try:
            redis_client = redis.StrictRedis()
            redis_client.ping()
            return {'status': 'healthy'}
        except Exception as e:
            return {'status': 'unhealthy', 'error': str(e)}
    
    def check_services(self):
        """ì™¸ë¶€ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        services = {}
        
        # SMS ì„œë¹„ìŠ¤
        services['sms'] = self.check_external_service('SMS_API_URL')
        
        # Email ì„œë¹„ìŠ¤
        services['email'] = self.check_external_service('EMAIL_API_URL')
        
        return services
    
    def get_health_status(self):
        """ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ"""
        return {
            'database': self.check_database(),
            'redis': self.check_redis(),
            'services': self.check_services(),
            'timestamp': timezone.now().isoformat()
        }
```

### 9.9 ë°°í¬ ì•„í‚¤í…ì²˜

#### 9.9.1 Docker ì»¨í…Œì´ë„ˆí™”
```dockerfile
# Dockerfile.backend
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„±
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Python ì˜ì¡´ì„±
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì•± ì½”ë“œ
COPY . .

# í™˜ê²½ ì„¤ì •
ENV PYTHONPATH=/app
ENV DJANGO_SETTINGS_MODULE=config.settings.production

# í—¬ìŠ¤ì²´í¬
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD python manage.py check || exit 1

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8000

# ì‹¤í–‰
CMD ["gunicorn", "--bind", "0.0.0.0:8000", "--workers", "4", "config.wsgi:application"]
```

```dockerfile
# Dockerfile.frontend
FROM node:18-alpine as builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

FROM nginx:alpine
COPY --from=builder /app/build /usr/share/nginx/html
COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
```

#### 9.9.2 Docker Compose êµ¬ì„±
```yaml
# docker-compose.yml
version: '3.8'

services:
  # ë°ì´í„°ë² ì´ìŠ¤
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: dn_solution2
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ìºì‹œ
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  # ë°±ì—”ë“œ API
  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    environment:
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/dn_solution2
      - REDIS_URL=redis://redis:6379
      - DEBUG=False
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      - media_files:/app/media
      - static_files:/app/static
    restart: unless-stopped

  # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
  celery:
    build:
      context: .
      dockerfile: Dockerfile.backend
    command: celery -A config worker -l info --concurrency=4
    environment:
      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/dn_solution2
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    volumes:
      - media_files:/app/media
    restart: unless-stopped

  # í”„ë¡ íŠ¸ì—”ë“œ
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.frontend
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - backend
    restart: unless-stopped

  # Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
      - static_files:/var/www/static
      - media_files:/var/www/media
    depends_on:
      - backend
      - frontend
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  media_files:
  static_files:
```

### 9.10 êµ¬í˜„ ë¡œë“œë§µ

#### 9.10.1 Phase 1: ì¸í”„ë¼ êµ¬ì¶• (4ì£¼)
```
Week 1-2: Docker ì»¨í…Œì´ë„ˆí™”
âœ… Dockerfile ì‘ì„±
âœ… Docker Compose êµ¬ì„±
âœ… ê°œë°œ/í”„ë¡œë•ì…˜ í™˜ê²½ ë¶„ë¦¬

Week 3-4: ìºì‹± ì‹œìŠ¤í…œ
âœ… Redis í´ëŸ¬ìŠ¤í„° êµ¬ì„±
âœ… ìºì‹± ë ˆì´ì–´ êµ¬í˜„
âœ… ìºì‹œ ë¬´íš¨í™” ì „ëµ
```

#### 9.10.2 Phase 2: ëª¨ë“ˆí™” (6ì£¼)
```
Week 1-2: ì„œë¹„ìŠ¤ ë¶„ë¦¬ ì¤€ë¹„
âœ… ìŠ¤í‚¤ë§ˆ ë¶„ë¦¬
âœ… ì„œë¹„ìŠ¤ ë ˆì´ì–´ êµ¬ì¡°í™”
âœ… API ê²½ê³„ ì •ì˜

Week 3-4: í•µì‹¬ ì„œë¹„ìŠ¤ ëª¨ë“ˆí™”
âœ… Policy Service ë¶„ë¦¬
âœ… Order Service ë¶„ë¦¬
âœ… Rebate Service ë¶„ë¦¬

Week 5-6: ì§€ì› ì„œë¹„ìŠ¤ ëª¨ë“ˆí™”
âœ… Report Service ë¶„ë¦¬
âœ… Notification Service ë¶„ë¦¬
âœ… API Gateway êµ¬í˜„
```

#### 9.10.3 Phase 3: ì„±ëŠ¥ ìµœì í™” (4ì£¼)
```
Week 1-2: ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
âœ… Read Replica êµ¬ì„±
âœ… ì¿¼ë¦¬ ìµœì í™”
âœ… ì¸ë±ìŠ¤ ìµœì í™”

Week 3-4: ì• í”Œë¦¬ì¼€ì´ì…˜ ìµœì í™”
âœ… ë¹„ë™ê¸° ì²˜ë¦¬ í™•ëŒ€
âœ… ë°°ì¹˜ ì‘ì—… ìµœì í™”
âœ… API ì‘ë‹µ ìµœì í™”
```

#### 9.10.4 Phase 4: ëª¨ë‹ˆí„°ë§ êµ¬ì¶• (3ì£¼)
```
Week 1: ë©”íŠ¸ë¦­ ìˆ˜ì§‘
âœ… Prometheus ì„¤ì •
âœ… ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ êµ¬í˜„
âœ… Grafana ëŒ€ì‹œë³´ë“œ

Week 2: ë¡œê¹… ì‹œìŠ¤í…œ
âœ… ELK Stack êµ¬ì„±
âœ… ë¡œê·¸ ìˆ˜ì§‘/ë¶„ì„
âœ… ì•Œë¦¼ ì‹œìŠ¤í…œ

Week 3: í—¬ìŠ¤ì²´í¬ ì‹œìŠ¤í…œ
âœ… ì„œë¹„ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§
âœ… ìë™ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜
âœ… SLA ëª¨ë‹ˆí„°ë§
```

#### 9.10.5 Phase 5: ë³´ì•ˆ ê°•í™” (2ì£¼)
```
Week 1: ì¸ì¦/ê¶Œí•œ ê°•í™”
âœ… JWT í† í° ê°œì„ 
âœ… ê¶Œí•œ ìºì‹± ìµœì í™”
âœ… API ë³´ì•ˆ ê°•í™”

Week 2: ë°ì´í„° ë³´ì•ˆ
âœ… ì•”í˜¸í™” ê°•í™”
âœ… ì·¨ì•½ì  ê²€ì‚¬
âœ… ë³´ì•ˆ ì •ì±… ìˆ˜ë¦½
```

ì´ ì•„í‚¤í…ì²˜ëŠ” í˜„ì¬ ëª¨ë†€ë¦¬ì‹ êµ¬ì¡°ì—ì„œ ë‹¨ê³„ì ìœ¼ë¡œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ë¡œ ì „í™˜í•  ìˆ˜ ìˆëŠ” í™•ì¥ ê°€ëŠ¥í•œ ì„¤ê³„ì…ë‹ˆë‹¤.